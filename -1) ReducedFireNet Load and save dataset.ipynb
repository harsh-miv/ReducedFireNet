{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This notebook downloads the dataset\n",
    "# Applies Data Augmentation\n",
    "# Saves final data: X and Y of length 450 after shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_accuracy = 'accuracies_our_model5.npy'\n",
    "path_to_f1score = 'f1score_our_model5.npy'\n",
    "path_to_test_indices = 'test_indices.npy'\n",
    "path_to_train_indices = 'train_indices.npy'\n",
    "path_to_X = 'X.npy'\n",
    "path_to_Y = 'Y.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling enum34-1.1.6:\n",
      "  Successfully uninstalled enum34-1.1.6\n",
      "Collecting gdown\n",
      "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm (from gdown)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/54/115f0c28a61d56674c3a5e05c46d6c3523ad196e1dcd3e2d8b119026df36/tqdm-4.54.1-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 12.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests[socks] (from gdown)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/fc/f91eac5a39a65f75a7adb58eac7fa78871ea9872283fb9c44e6545998134/requests-2.25.0-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 17.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock (from gdown)\n",
      "  Downloading https://files.pythonhosted.org/packages/93/83/71a2ee6158bb9f39a90c0dea1637f81d5eef866e188e1971a1b1ab01a35a/filelock-3.0.12-py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.11.0)\n",
      "Collecting certifi>=2017.4.17 (from requests[socks]->gdown)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/a0/5f06e1e1d463903cf0c0eebeb751791119ed7a4b3737fdc9a77f1cdfb51f/certifi-2020.12.5-py2.py3-none-any.whl (147kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 31.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<4,>=3.0.2 (from requests[socks]->gdown)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 33.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests[socks]->gdown)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/71/45d36a8df68f3ebb098d6861b2c017f3d094538c0fb98fa61d4dc43e69b9/urllib3-1.26.2-py2.py3-none-any.whl (136kB)\n",
      "\u001b[K     |████████████████████████████████| 143kB 32.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests[socks]->gdown) (2.6)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6; extra == \"socks\" (from requests[socks]->gdown)\n",
      "  Downloading https://files.pythonhosted.org/packages/8d/59/b4572118e098ac8e46e399a1dd0f2d85403ce8bbaad9ec79373ed6badaf9/PySocks-1.7.1-py3-none-any.whl\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-3.12.2-cp36-none-any.whl size=9681 sha256=c73bb0236081f23411d8bac82246954c9d9cb876c1993d2515b6eb2afbc27919\n",
      "  Stored in directory: /root/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
      "Successfully built gdown\n",
      "Installing collected packages: tqdm, certifi, chardet, urllib3, PySocks, requests, filelock, gdown\n",
      "Successfully installed PySocks-1.7.1 certifi-2020.12.5 chardet-3.0.4 filelock-3.0.12 gdown-3.12.2 requests-2.25.0 tqdm-4.54.1 urllib3-1.26.2\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pillow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/19/d4c25111d36163698396f93c363114cf1cddbacb24744f6612f25b6aa3d0/Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 13.4MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pillow\n",
      "Successfully installed pillow-8.0.1\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/a1/273def87037a7fb010512bbc5901c31cfddfca8080bc63b42b26e3cc55b3/scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8MB 23.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 24.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.2)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting scipy>=0.19.1 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/89/63171228d5ced148f5ced50305c89e8576ffc695a90b58fe5bb602b910c2/scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9MB 16.5MB/s eta 0:00:01     |██████████████████████████▋     | 21.6MB 16.5MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: joblib, threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed joblib-0.17.0 scikit-learn-0.23.2 scipy-1.5.4 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y enum34\n",
    "!pip install gdown\n",
    "!pip install pillow\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=173oK0fD29D-opBV6v-GvBBG4TE4FF-mB\n",
      "To: /notebooks/lymphoma-kaggle.zip\n",
      "1.44GB [00:34, 42.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown --id 173oK0fD29D-opBV6v-GvBBG4TE4FF-mB\n",
    "!unzip -q lymphoma-kaggle.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 11 08:48:14 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        On   | 00000000:00:05.0 Off |                  Off |\n",
      "| 26%   22C    P8     6W / 180W |      1MiB / 16278MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# This cell should output the graphic card details\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Checking if GPU is detected or not\n",
    "# This cell should output: \n",
    "# Default GPU Device: /device:GPU:0\n",
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 150 # For each class type, we will have 'total' number of images\n",
    "rootdir = 'lymphoma-kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function applies data augmentation\n",
    "\n",
    "def get_req_dataset(X):\n",
    "    req = total - len(X)\n",
    "    X_array = np.array(X)\n",
    "    datagen = ImageDataGenerator(brightness_range=[0.5,1.5], horizontal_flip=True, vertical_flip=True)\n",
    "    aug_iter = datagen.flow(X_array, batch_size=1)\n",
    " \n",
    "    for i in range(req):\n",
    "        curr_aug_img = next(aug_iter)[0].astype('uint8')\n",
    "        X.append(curr_aug_img)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromFile():\n",
    "    \n",
    "    X_CLL = []\n",
    "    X_FL = []\n",
    "    X_MCL = []\n",
    "    \n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            curr_img_path = os.path.join(subdir, file)\n",
    "            curr_img_path = os.path.normpath(curr_img_path)\n",
    "            img = image.load_img(curr_img_path)\n",
    "            img = image.img_to_array(img)\n",
    "            className = curr_img_path.split('/')[1]\n",
    "            if(className == 'CLL'):\n",
    "                X_CLL.append(img)\n",
    "            elif(className == 'FL'):\n",
    "                X_FL.append(img)\n",
    "            elif(className == 'MCL'):\n",
    "                X_MCL.append(img)\n",
    "    \n",
    "    X_CLL = get_req_dataset(X_CLL)\n",
    "    X_FL = get_req_dataset(X_FL)\n",
    "    X_MCL = get_req_dataset(X_MCL)\n",
    "    \n",
    "    return X_CLL, X_FL, X_MCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY():\n",
    "    \n",
    "    X_CLL, X_FL, X_MCL = getDataFromFile()\n",
    "    \n",
    "    XX = []\n",
    "    YY = []\n",
    "\n",
    "    classes = {}\n",
    "    classes['CLL'] = 0\n",
    "    classes['FL'] = 1\n",
    "    classes['MCL'] = 2\n",
    "\n",
    "    for i in range(len(X_CLL)):\n",
    "        XX.append(X_CLL[i])\n",
    "        YY.append(classes['CLL'])\n",
    "\n",
    "    for i in range(len(X_FL)):\n",
    "        XX.append(X_FL[i])\n",
    "        YY.append(classes['FL'])\n",
    "\n",
    "    for i in range(len(X_MCL)):\n",
    "        XX.append(X_MCL[i])\n",
    "        YY.append(classes['MCL'])\n",
    "\n",
    "    X = np.array(XX)\n",
    "    Y = np.array(YY)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFinalDataset():\n",
    "    X, Y = getXY()\n",
    "    # Currently we first have 150 CCL, 150 FL and 150 MCL in the same order  \n",
    "    # Shuffle them to get random order\n",
    "    X, Y = shuffle(X, Y, random_state = 0)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 1040, 1388, 3)\n",
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = getFinalDataset()\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "train_indices = []s\n",
    "test_indices = []\n",
    "\n",
    "for train_index, test_index in kfold.split(X, Y):\n",
    "    train_indices.append(train_index)\n",
    "    test_indices.append(test_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "f1scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 360)\n",
      "(5, 90)\n",
      "(0,)\n",
      "[]\n",
      "(0,)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.array(train_indices)\n",
    "test_indices = np.array(test_indices)\n",
    "accuracies = np.array(accuracies)\n",
    "f1scores = np.array(f1scores)\n",
    "\n",
    "print(train_indices.shape)\n",
    "print(test_indices.shape)\n",
    "print(accuracies.shape)\n",
    "print(accuracies)\n",
    "print(f1scores.shape)\n",
    "print(f1scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_to_train_indices, train_indices)\n",
    "np.save(path_to_test_indices, test_indices)\n",
    "np.save(path_to_accuracy, accuracies)\n",
    "np.save(path_to_f1score, f1scores)\n",
    "np.save(path_to_X, X)\n",
    "\n",
    "Y = to_categorical(Y)\n",
    "np.save(path_to_Y, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 1040, 1388, 3)\n",
      "(450, 3)\n"
     ]
    }
   ],
   "source": [
    "ss = np.load(path_to_X)\n",
    "print(ss.shape)\n",
    "\n",
    "tt = np.load(path_to_Y)\n",
    "print(tt.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
