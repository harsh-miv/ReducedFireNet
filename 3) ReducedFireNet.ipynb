{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D, concatenate\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_accuracy = 'accuracies_our_model5.npy'\n",
    "path_to_f1score = 'f1score_our_model5.npy'\n",
    "path_to_test_indices = 'test_indices.npy'\n",
    "path_to_train_indices = 'train_indices.npy'\n",
    "path_to_X = 'X.npy'\n",
    "path_to_Y = 'Y.npy'\n",
    "\n",
    "fold_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_height = 128\n",
    "global_width = 128\n",
    "input_channels = 3\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fire(x, squeeze, expand):\n",
    "    y  = Conv2D(filters=squeeze, kernel_size=1, activation='relu', padding='same')(x)\n",
    "    y1 = Conv2D(filters=expand//2, kernel_size=1, activation='relu', padding='same')(y)\n",
    "    y3 = Conv2D(filters=expand//2, kernel_size=3, activation='relu', padding='same')(y)\n",
    "    return concatenate([y1, y3])\n",
    "\n",
    "def fire_module(squeeze, expand):\n",
    "    return lambda x: fire(x, squeeze, expand)\n",
    "\n",
    "def get_model():\n",
    "    x = Input(shape = [global_height, global_width, input_channels])\n",
    "\n",
    "    y = Conv2D(kernel_size=3, filters=32, padding='same', use_bias=True, activation='relu')(x)\n",
    "    y = fire_module(16, 32)(y)\n",
    "    y = MaxPooling2D(pool_size=2)(y)\n",
    "    y = fire_module(24, 48)(y)\n",
    "    y = MaxPooling2D(pool_size=2)(y)\n",
    "\n",
    "    y = Dropout(0.1)(y)\n",
    "\n",
    "    y = fire_module(24, 48)(y)\n",
    "    y = MaxPooling2D(pool_size=2)(y)\n",
    "    y = fire_module(16, 32)(y)\n",
    "    y = GlobalAveragePooling2D()(y)\n",
    "    y = Dense(num_classes, activation='softmax')(y)\n",
    "\n",
    "    model = Model(x, y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.load(path_to_train_indices)\n",
    "test_indices = np.load(path_to_test_indices)\n",
    "accuracies = np.load(path_to_accuracy)\n",
    "f1scores = np.load(path_to_f1score)\n",
    "\n",
    "train_index = train_indices[fold_idx]\n",
    "test_index = test_indices[fold_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(img, new_height, new_width):\n",
    "  height, width, depth = img.shape \n",
    "  patches = []\n",
    "\n",
    "  for r in range(0, height, new_height):\n",
    "    for c in range(0, width, new_width):\n",
    "      if r+new_height <= height and c+new_width <= width:\n",
    "        curr_patch = img[r: r+new_height, c: c+new_width, :]\n",
    "        patches.append(curr_patch)\n",
    "        \n",
    "  return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test():\n",
    "    \n",
    "    X = np.load(path_to_X)\n",
    "    Y = np.load(path_to_Y)\n",
    "    \n",
    "    print('X: ', X.shape)\n",
    "    print('Y: ', Y.shape)\n",
    "    print()\n",
    "    \n",
    "    X_train = X[train_index]\n",
    "    Y_train = Y[train_index]\n",
    "    \n",
    "    X_test = X[test_index]\n",
    "    Y_test = Y[test_index]\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCompleteDataset():\n",
    "    X_train, X_test, Y_train, Y_test = get_train_test()\n",
    "    \n",
    "    print('X Train:', X_train.shape)\n",
    "    print('Y Train:', Y_train.shape)\n",
    "    \n",
    "    print('X Test:', X_test.shape)\n",
    "    print('Y Test:', Y_test.shape)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    X_train_patches = []\n",
    "    Y_train_patches = []\n",
    "    \n",
    "    for i in range(0, len(X_train), 1):\n",
    "        patches = get_patches(X_train[i], global_height, global_width)\n",
    "        numOfPatches = len(patches)\n",
    "        for p in patches:\n",
    "            X_train_patches.append(p)\n",
    "            Y_train_patches.append(Y_train[i])\n",
    "    \n",
    "    numOfPatches = len(get_patches(X_train[0], global_height, global_width))\n",
    "    print('One image creates no. of patches: ', numOfPatches)\n",
    "    print()\n",
    "    \n",
    "    X_train_patches = np.array(X_train_patches)\n",
    "    Y_train_patches = np.array(Y_train_patches)\n",
    "    \n",
    "    # Shuffling the training patch data alongwith their label\n",
    "    X_train_patches, Y_train_patches = shuffle(X_train_patches, Y_train_patches, random_state = 0)\n",
    "    \n",
    "    return X_train_patches, Y_train_patches, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (450, 1040, 1388, 3)\n",
      "Y:  (450, 3)\n",
      "\n",
      "X Train: (360, 1040, 1388, 3)\n",
      "Y Train: (360, 3)\n",
      "X Test: (90, 1040, 1388, 3)\n",
      "Y Test: (90, 3)\n",
      "\n",
      "One image creates no. of patches:  80\n",
      "\n",
      "Training Data in patches:  (28800, 128, 128, 3) (28800, 3)\n",
      "One training patch size:  (128, 128, 3) (3,)\n",
      "Original test data:  (90, 1040, 1388, 3) (90, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_patches, Y_train_patches, X_test, Y_test = getCompleteDataset()\n",
    "print('Training Data in patches: ',X_train_patches.shape, Y_train_patches.shape)\n",
    "print('One training patch size: ', X_train_patches[0].shape, Y_train_patches[0].shape)\n",
    "print('Original test data: ', X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          30147        8398       20674         608        1073       20766\n",
      "Swap:             0           0           0\n"
     ]
    }
   ],
   "source": [
    "!free -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_run():\n",
    "    \n",
    "    model = get_model()\n",
    "    \n",
    "    model.compile(optimizers.Adam(lr=0.0005),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    \n",
    "    history = model.fit(X_train_patches, Y_train_patches, epochs = 30)\n",
    "    \n",
    "    y_test_pred = []\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        patches = get_patches(X_test[i], global_height, global_width)\n",
    "        patches = np.array(patches)\n",
    "        curr_pred = model.predict(patches)\n",
    "\n",
    "        curr_pred_single = np.argmax(curr_pred, axis=1)\n",
    "        max_occurring_class = np.bincount(curr_pred_single).argmax()\n",
    "\n",
    "        y_test_pred.append(max_occurring_class)\n",
    "\n",
    "    y_test_pred = np.array(y_test_pred)\n",
    "    y_test = np.argmax(Y_test, axis=1)\n",
    "    \n",
    "    confusion_matrix_var = confusion_matrix(y_test, y_test_pred)\n",
    "    accuracy_var = accuracy_score(y_test, y_test_pred)\n",
    "    classification_report_var = classification_report(y_test, y_test_pred)\n",
    "    \n",
    "    f1score_var = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    return accuracy_var, confusion_matrix_var, classification_report_var, f1score_var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28800 samples\n",
      "Epoch 1/30\n",
      "28800/28800 [==============================] - 34s 1ms/sample - loss: 0.8644 - accuracy: 0.5692\n",
      "Epoch 2/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.5524 - accuracy: 0.7515\n",
      "Epoch 3/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.4350 - accuracy: 0.8194\n",
      "Epoch 4/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.3610 - accuracy: 0.8533\n",
      "Epoch 5/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.3094 - accuracy: 0.8780\n",
      "Epoch 6/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.2721 - accuracy: 0.8962\n",
      "Epoch 7/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.2506 - accuracy: 0.9024\n",
      "Epoch 8/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.2249 - accuracy: 0.9145\n",
      "Epoch 9/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.2138 - accuracy: 0.9177s - loss: 0.2133 \n",
      "Epoch 10/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1978 - accuracy: 0.9259\n",
      "Epoch 11/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1809 - accuracy: 0.9324\n",
      "Epoch 12/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1633 - accuracy: 0.9405\n",
      "Epoch 13/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1694 - accuracy: 0.9368\n",
      "Epoch 14/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1421 - accuracy: 0.9488\n",
      "Epoch 15/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1459 - accuracy: 0.9477\n",
      "Epoch 16/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1298 - accuracy: 0.9541\n",
      "Epoch 17/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1270 - accuracy: 0.9540\n",
      "Epoch 18/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1270 - accuracy: 0.9541\n",
      "Epoch 19/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1127 - accuracy: 0.9600\n",
      "Epoch 20/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1109 - accuracy: 0.9601\n",
      "Epoch 21/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1049 - accuracy: 0.9618\n",
      "Epoch 22/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.1053 - accuracy: 0.9628\n",
      "Epoch 23/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.0942 - accuracy: 0.9656\n",
      "Epoch 24/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.0948 - accuracy: 0.9666\n",
      "Epoch 25/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.0858 - accuracy: 0.9690\n",
      "Epoch 26/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.0829 - accuracy: 0.9699\n",
      "Epoch 27/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.0878 - accuracy: 0.9679\n",
      "Epoch 28/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.0771 - accuracy: 0.9726\n",
      "Epoch 29/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.0828 - accuracy: 0.9709\n",
      "Epoch 30/30\n",
      "28800/28800 [==============================] - 29s 1ms/sample - loss: 0.0740 - accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "accuracy_var, confusion_matrix_var, classification_report_var, f1score_var = model_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  0  0]\n",
      " [ 1 28  1]\n",
      " [ 1  0 29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        30\n",
      "           1       1.00      0.93      0.97        30\n",
      "           2       0.97      0.97      0.97        30\n",
      "\n",
      "    accuracy                           0.97        90\n",
      "   macro avg       0.97      0.97      0.97        90\n",
      "weighted avg       0.97      0.97      0.97        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix_var)\n",
    "print(classification_report_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the accuracy to the 'accuracies' variable and save it in a file\n",
    "# Similarly for F1 score\n",
    "\n",
    "accuracies = np.append(accuracies, accuracy_var)\n",
    "np.save(path_to_accuracy, accuracies)\n",
    "\n",
    "f1scores = np.append(f1scores, f1score_var)\n",
    "np.save(path_to_f1score, f1scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold number:  0\n",
      "Accuracy:  0.9888888888888889\n",
      "\n",
      "\n",
      "\n",
      "For fold number:  1\n",
      "Accuracy:  0.9444444444444444\n",
      "\n",
      "\n",
      "\n",
      "For fold number:  2\n",
      "Accuracy:  0.9777777777777777\n",
      "\n",
      "\n",
      "\n",
      "For fold number:  3\n",
      "Accuracy:  0.9666666666666667\n",
      "\n",
      "\n",
      "\n",
      "Average Accuracy:  0.9694444444444444\n"
     ]
    }
   ],
   "source": [
    "# Print all the accuracies accumulated till now\n",
    "accuracies = np.load(path_to_accuracy)\n",
    "for i in range(len(accuracies)):\n",
    "    print('For fold number: ', i)\n",
    "    print('Accuracy: ', accuracies[i])\n",
    "    print('\\n'*2)\n",
    "\n",
    "print('Average Accuracy: ', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For fold number:  0\n",
      "F1 Score:  0.9888858016115588\n",
      "\n",
      "\n",
      "\n",
      "For fold number:  1\n",
      "F1 Score:  0.9441893258374847\n",
      "\n",
      "\n",
      "\n",
      "For fold number:  2\n",
      "F1 Score:  0.9779478767997085\n",
      "\n",
      "\n",
      "\n",
      "For fold number:  3\n",
      "F1 Score:  0.9666419478432827\n",
      "\n",
      "\n",
      "\n",
      "Average F1 score:  0.9694162380230086\n"
     ]
    }
   ],
   "source": [
    "# Print all the f1 scores accumulated till now\n",
    "f1scores = np.load(path_to_f1score)\n",
    "for i in range(len(f1scores)):\n",
    "    print('For fold number: ', i)\n",
    "    print('F1 Score: ', f1scores[i])\n",
    "    print('\\n'*2)\n",
    "\n",
    "print('Average F1 score: ', np.mean(f1scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
